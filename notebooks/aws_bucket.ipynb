{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumping the txt data into json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files_path = glob.glob('../data/preprocessed/*.txt')\n",
    "text_files_lines = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_file_path in text_files_path:\n",
    "    with open(text_file_path, encoding='utf-8') as textfile:\n",
    "        lines = textfile.readlines()\n",
    "        text_files_lines.extend(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unicode_amharic_range = (4608, 4955)\n",
    "def remove_chars(sentence:str) -> str:\n",
    "    new_sentence = ''\n",
    "    for char in sentence:\n",
    "        if(ord(char) >= unicode_amharic_range[0] and ord(char) <= unicode_amharic_range[1] or ord(char) == 32):\n",
    "            new_sentence += char\n",
    "\n",
    "    new_sentence.replace(\"  \",\" \")\n",
    "    new_sentence = new_sentence.strip()\n",
    "\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = list(map(remove_chars, text_files_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus = {}\n",
    "for i in range(len(cleaned_text)):\n",
    "    text_corpus[i] = cleaned_text[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186276"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ዋናዎቹ ዜና ማርቆስ እንዳለው የግእዝ ቋንቋ መግቢያ ጥንታዊ ግእዝ በዘመናዊ አቀራረብ ቅኔ ለወጣቶች እና ግእዝ ቋንቋ ላራተኛ ክፍል በሚባሉ መፃህፍቶቻቸው'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_corpus[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_dictionary(dictionary:dict, size:int) -> list:\n",
    "    partitions = []\n",
    "    # divide texts to dynamic dictionary partitions\n",
    "    index = 0\n",
    "    while len(dictionary) > (index * size) + size:\n",
    "        print((index * size) + size)\n",
    "        start = (index * size)\n",
    "        end = start + size\n",
    "        print('start: ',start)\n",
    "        print('end: ',end)\n",
    "        parition = dict(list(dictionary.items())[start:end])\n",
    "        partitions.append(parition)\n",
    "        index += 1\n",
    "\n",
    "    partitions.append(dict(list(dictionary.items())[end:]))\n",
    "\n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "start:  0\n",
      "end:  10000\n",
      "20000\n",
      "start:  10000\n",
      "end:  20000\n",
      "30000\n",
      "start:  20000\n",
      "end:  30000\n",
      "40000\n",
      "start:  30000\n",
      "end:  40000\n",
      "50000\n",
      "start:  40000\n",
      "end:  50000\n",
      "60000\n",
      "start:  50000\n",
      "end:  60000\n",
      "70000\n",
      "start:  60000\n",
      "end:  70000\n",
      "80000\n",
      "start:  70000\n",
      "end:  80000\n",
      "90000\n",
      "start:  80000\n",
      "end:  90000\n",
      "100000\n",
      "start:  90000\n",
      "end:  100000\n",
      "110000\n",
      "start:  100000\n",
      "end:  110000\n",
      "120000\n",
      "start:  110000\n",
      "end:  120000\n",
      "130000\n",
      "start:  120000\n",
      "end:  130000\n",
      "140000\n",
      "start:  130000\n",
      "end:  140000\n",
      "150000\n",
      "start:  140000\n",
      "end:  150000\n",
      "160000\n",
      "start:  150000\n",
      "end:  160000\n",
      "170000\n",
      "start:  160000\n",
      "end:  170000\n",
      "180000\n",
      "start:  170000\n",
      "end:  180000\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "text_corpus_partitions = partition_dictionary(text_corpus, 10000)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_corpus_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_corpus_partitions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_partitions(partitions: list):\n",
    "    index = 0\n",
    "    for partition in partitions:\n",
    "        with open(f'../data/preprocessed1/data_{index}.json', mode='w' ,encoding='utf-8') as obj:\n",
    "            json.dump(partition, obj, ensure_ascii=False, indent=4)\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_partitions(text_corpus_partitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing the json on the BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "sys.path.insert(0, '../scripts/')\n",
    "sys.path.insert(0, '../logs/')\n",
    "from aws_bucket import AWSClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = glob.glob('../data/preprocessed1/*.json')\n",
    "file_names = list(map(lambda x: x.split('\\\\')[0], file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_client = AWSClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred (AccessDenied) when calling the ListObjects operation: Access Denied\n"
     ]
    }
   ],
   "source": [
    "file_exist = aws_client.get_file_names('chang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f9214e18a48aa364c10c79306e38d719ccf6d53001c1a0ba8771dd8d1ae734d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
